{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = [[1, 2, 1], [1, 3, 2], [1, 3, 4], [1, 5, 5], \n",
    "          [1, 7, 5], [1, 2, 5], [1, 6, 6], [1, 7, 7]]\n",
    "y_data = [[0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 0], \n",
    "          [0, 1, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0]]\n",
    "\n",
    "# Evaluation our model using this test dataset\n",
    "x_test = [[2, 1, 1], [3, 1, 2], [3, 3, 4]]\n",
    "y_test = [[0, 0, 1], [0, 0, 1], [0, 0, 1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\",[None,3])\n",
    "Y = tf.placeholder(\"float\",[None,3])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3,3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "cost = tf.reduce_mean( -tf.reduce_sum(Y * tf.log(hypothesis),axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Correct prediction Test model\n",
    "\n",
    "## arg_max function\n",
    "\n",
    "arg_max(\n",
    "    input,\n",
    "    dimension,\n",
    "    name=None\n",
    ")\n",
    "\n",
    "Returns the index with the largest value across dimensions of a tensor.\n",
    "返回在张量的尺寸上具有最大值的索引\n",
    "\n",
    "# correct_prediction = tf.equal(tf.arg_max(hypothesis,1),tf.arg_max(Y,1))\n",
    "Returns the index with the largest value across axes of a tensor.\n",
    "for we use 'softmax_cross_entropy_with_logits',\n",
    "the prediction are presented as the paobability\n",
    "by the argmax function we will get the index of largest probability of prediction\n",
    "but why we need use tf.arg_max(Y,1)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "prediction = tf.arg_max(hypothesis,1)\n",
    "is_correct = tf.equal(prediction,tf.arg_max(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  0 cost_val:  7.31662 \n",
      " [[-0.68406874  0.75542504 -0.80705446]\n",
      " [-0.10571302  0.65812552 -0.59445602]\n",
      " [-1.14200139 -2.67441535  0.82745177]]\n",
      "step:  20 cost_val:  1.32021 \n",
      " [[-0.68334168  0.6520744  -0.70443094]\n",
      " [ 0.23146959  0.58123231 -0.85474533]\n",
      " [-0.74565381 -1.78859437 -0.45471665]]\n",
      "step:  40 cost_val:  0.903405 \n",
      " [[-0.75569719  0.49936181 -0.47936308]\n",
      " [ 0.19915093  0.22402082 -0.46521506]\n",
      " [-0.70933485 -1.3648262  -0.9148035 ]]\n",
      "step:  60 cost_val:  0.734453 \n",
      " [[-0.83102334  0.38582042 -0.2904956 ]\n",
      " [ 0.17799838  0.03061639 -0.25065795]\n",
      " [-0.66760868 -1.12296295 -1.19839287]]\n",
      "step:  80 cost_val:  0.668113 \n",
      " [[-0.90378022  0.30077133 -0.13268957]\n",
      " [ 0.16146839 -0.04716113 -0.15635048]\n",
      " [-0.62252873 -1.00698638 -1.35944963]]\n",
      "step:  100 cost_val:  0.631634 \n",
      " [[-0.97408336  0.23513389  0.00325097]\n",
      " [ 0.14818582 -0.07318466 -0.11704438]\n",
      " [-0.57976276 -0.95025533 -1.45894647]]\n",
      "step:  120 cost_val:  0.606179 \n",
      " [[-1.04265654  0.18360801  0.12335014]\n",
      " [ 0.13864879 -0.07832248 -0.10236955]\n",
      " [-0.54138029 -0.92031133 -1.52727306]]\n",
      "step:  140 cost_val:  0.586274 \n",
      " [[-1.10985446  0.14279607  0.2313599 ]\n",
      " [ 0.13254416 -0.07537169 -0.09921569]\n",
      " [-0.50726426 -0.90304524 -1.57865524]]\n",
      "step:  160 cost_val:  0.569786 \n",
      " [[-1.1758002   0.11031834  0.32978341]\n",
      " [ 0.12909308 -0.06962004 -0.10151628]\n",
      " [-0.47660345 -0.89217168 -1.62018943]]\n",
      "step:  180 cost_val:  0.555647 \n",
      " [[-1.24052858  0.08442778  0.42040253]\n",
      " [ 0.12748174 -0.06322785 -0.10629711]\n",
      " [-0.44852993 -0.88478655 -1.65564811]]\n",
      "step:  200 cost_val:  0.54323 \n",
      " [[-1.30405426  0.06380999  0.50454575]\n",
      " [ 0.12704542 -0.05703456 -0.11205392]\n",
      " [-0.42232993 -0.8794921  -1.68714249]]\n",
      "Prediction:  [2 2 2]\n",
      "Accurancy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# launch graph\n",
    "with tf.Session() as sess:   # error Session()\n",
    "    # Initialize Tensorflow Variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run([cost, W, optimizer],\n",
    "                                     feed_dict={X:x_data,Y:y_data})\n",
    "        if step % 20 == 0:\n",
    "            print(\"step: \", step, \"cost_val: \", cost_val, \"\\n\", W_val)\n",
    "    \n",
    "    # predict\n",
    "    print(\"Prediction: \", sess.run(prediction, feed_dict= {X: x_test}))\n",
    "    # Calculate the accuracy\n",
    "    print(\"Accurancy: \", sess.run(accuracy, feed_dict= {X:x_test, Y: y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate\n",
    "###### Large learning rate : Overshooting\n",
    "###### Small learning rate : Many iterations until covergence and trapping in local minima\n",
    "\n",
    "### try to change the learning rate at 1.5 or 1e-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Nomalized inputs vs Non-N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# non_normalized inputs\n",
    "\n",
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "              [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "              [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "              [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "              [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "              [819, 823, 1198100, 816, 820.450012],\n",
    "              [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "              [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the inputs xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MinMaxScaler(data):\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    # noise term prevents the zero division\n",
    "    return numerator / (denominator + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.99999999  0.99999999  0.          1.          1.        ]\n",
      " [ 0.70548491  0.70439552  1.          0.71881782  0.83755791]\n",
      " [ 0.54412549  0.50274824  0.57608696  0.606468    0.6606331 ]\n",
      " [ 0.33890353  0.31368023  0.10869565  0.45989134  0.43800918]\n",
      " [ 0.51436     0.42582389  0.30434783  0.58504805  0.42624401]\n",
      " [ 0.49556179  0.42582389  0.31521739  0.48131134  0.49276137]\n",
      " [ 0.11436064  0.          0.20652174  0.22007776  0.18597238]\n",
      " [ 0.          0.07747099  0.5326087   0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "xy = MinMaxScaler(xy)\n",
    "print(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  6.10542 \n",
      "Prediction:\n",
      " [[-3.42465353]\n",
      " [-2.46258831]\n",
      " [-1.901227  ]\n",
      " [-1.28815567]\n",
      " [-1.72189927]\n",
      " [-1.49801779]\n",
      " [-0.31831166]\n",
      " [ 0.00527349]]\n",
      "500 Cost:  5.89861 \n",
      "Prediction:\n",
      " [[-3.36354065]\n",
      " [-2.40538287]\n",
      " [-1.85370564]\n",
      " [-1.25157619]\n",
      " [-1.67820227]\n",
      " [-1.45596313]\n",
      " [-0.29142073]\n",
      " [ 0.03104682]]\n",
      "1000 Cost:  5.69947 \n",
      "Prediction:\n",
      " [[-3.30354261]\n",
      " [-2.34925771]\n",
      " [-1.80708539]\n",
      " [-1.21569622]\n",
      " [-1.6353327 ]\n",
      " [-1.4147079 ]\n",
      " [-0.26506683]\n",
      " [ 0.05629282]]\n",
      "1500 Cost:  5.50775 \n",
      "Prediction:\n",
      " [[-3.24464226]\n",
      " [-2.2941947 ]\n",
      " [-1.76135159]\n",
      " [-1.18050325]\n",
      " [-1.59327638]\n",
      " [-1.37423837]\n",
      " [-0.23923969]\n",
      " [ 0.08102126]]\n",
      "2000 Cost:  5.32313 \n",
      "Prediction:\n",
      " [[-3.18681335]\n",
      " [-2.24017048]\n",
      " [-1.71648443]\n",
      " [-1.14598298]\n",
      " [-1.5520159 ]\n",
      " [-1.33453739]\n",
      " [-0.2139293 ]\n",
      " [ 0.10524245]]\n"
     ]
    }
   ],
   "source": [
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "W = tf.Variable(tf.random_normal([4, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "       [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 500 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epoches = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,[None, 784])\n",
    "Y = tf.placeholder(tf.float32,[None, 10])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784,256]))\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "L1 = tf.nn.relu(tf.matmul(X,W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256,256]))\n",
    "b2 = tf.Variable(tf.random_normal([256]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1,W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256,10]))\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L2,W3) + b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits=hypothesis,labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost =  184.087123\n",
      "Epoch: 0002 cost =  43.8269127\n",
      "Epoch: 0003 cost =  27.3890535\n",
      "Epoch: 0004 cost =  18.8421832\n",
      "Epoch: 0005 cost =  13.8706492\n",
      "Epoch: 0006 cost =  10.3013691\n",
      "Epoch: 0007 cost =  7.81531142\n",
      "Epoch: 0008 cost =  5.71691044\n",
      "Epoch: 0009 cost =  4.35253803\n",
      "Epoch: 0010 cost =  3.28495284\n",
      "Epoch: 0011 cost =  2.4136374\n",
      "Epoch: 0012 cost =  1.82907857\n",
      "Epoch: 0013 cost =  1.38899347\n",
      "Epoch: 0014 cost =  1.12735805\n",
      "Epoch: 0015 cost =  0.863518323\n",
      "Learning finished!\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(training_epoches):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs,Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer],feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "    print('Epoch:','%04d'%(epoch+1),'cost = ','{:.09}'.format(avg_cost)) ## error{}\n",
    "print('Learning finished!')       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test model and check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.947\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(hypothesis,1),tf.argmax(Y,1))\n",
    "# Returns the index with the largest value across axes of a tensor.\n",
    "# for we use 'softmax_cross_entropy_with_logits',\n",
    "# the prediction are presented as the paobability\n",
    "# by the argmax function we will get the index of largest probability of prediction\n",
    "# but why we need use tf.arg_max(Y,1)?\n",
    "accracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "print('Accuracy:',sess.run(accracy,feed_dict={X: mnist.test.images, \n",
    "                                             Y: mnist.test.labels}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get one picture, predict then draw a picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: [2]\n",
      "Prediction: [2]\n"
     ]
    }
   ],
   "source": [
    "r = random.randint(0,mnist.test.num_examples - 1)\n",
    "mnist_test = mnist.test\n",
    "label = mnist_test.labels[r:r+1]\n",
    "image = mnist_test.images[r:r+1]\n",
    "print(\"Label:\", sess.run(tf.argmax(label,1)))\n",
    "print(\"Prediction:\",sess.run(\n",
    "      tf.argmax(hypothesis,1),feed_dict={X:image}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b56786be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.reshape(28,28),cmap='Greys',interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

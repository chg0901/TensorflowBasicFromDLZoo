{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble prediction\n",
    "\n",
    "    ### Train `num` independt models, then sum the prediction probability, then `argmax` it to the prediction result\n",
    "## 1. prepare the model\n",
    "## 2. train our ensemble model\n",
    "    ### Training result 1\n",
    "    ### Training result 2\n",
    "\n",
    "## 4. Compare the result of trainging with dropout between the conv. layers\n",
    "    ### Training result \n",
    "    ### Training result (without)   \n",
    "\n",
    "## 3. without dropout between the convolution layer\n",
    "    ### Training result 1\n",
    "    ### Training result 2\n",
    "    \n",
    "    \n",
    "What's more, we find that training the model with **pycharm** instead the jupyter notebook, we can get faster training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Learning Started!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 20\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        self._build_net()\n",
    "\n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            # dropout (keep_prob) rate  0.7~0.5 on training, but should be 1\n",
    "            # for testing\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "\n",
    "            # input place holders\n",
    "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "            # img 28x28x1 (black/white), Input Layer\n",
    "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "            # Convolutional Layer #1\n",
    "            conv1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3, 3],\n",
    "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
    "            # Pooling Layer #1\n",
    "            pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
    "                                            padding=\"SAME\", strides=2)\n",
    "            dropout1 = tf.layers.dropout(inputs=pool1,\n",
    "                                         rate=0.7, training=self.training)\n",
    "\n",
    "            # Convolutional Layer #2 and Pooling Layer #2\n",
    "            conv2 = tf.layers.conv2d(inputs=dropout1, filters=64, kernel_size=[3, 3],\n",
    "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
    "            pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
    "                                            padding=\"SAME\", strides=2)\n",
    "            dropout2 = tf.layers.dropout(inputs=pool2,\n",
    "                                         rate=0.7, training=self.training)\n",
    "\n",
    "            # Convolutional Layer #2 and Pooling Layer #2\n",
    "            conv3 = tf.layers.conv2d(inputs=dropout2, filters=128, kernel_size=[3, 3],\n",
    "                                     padding=\"same\", activation=tf.nn.relu)\n",
    "            pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2],\n",
    "                                            padding=\"same\", strides=2)\n",
    "            dropout3 = tf.layers.dropout(inputs=pool3,\n",
    "                                         rate=0.7, training=self.training)\n",
    "\n",
    "            # Dense Layer with Relu\n",
    "            flat = tf.reshape(dropout3, [-1, 128 * 4 * 4])\n",
    "            dense4 = tf.layers.dense(inputs=flat,\n",
    "                                     units=625, activation=tf.nn.relu)\n",
    "            dropout4 = tf.layers.dropout(inputs=dense4,\n",
    "                                         rate=0.5, training=self.training)\n",
    "\n",
    "            # Logits (no activation) Layer: L5 Final FC 625 inputs -> 10 outputs\n",
    "            self.logits = tf.layers.dense(inputs=dropout4, units=10)\n",
    "\n",
    "        # define cost/loss & optimizer\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=self.logits, labels=self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=learning_rate).minimize(self.cost)\n",
    "\n",
    "        correct_prediction = tf.equal(\n",
    "            tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def predict(self, x_test, training=False):\n",
    "        return self.sess.run(self.logits,\n",
    "                             feed_dict={self.X: x_test, self.training: training})\n",
    "\n",
    "    def get_accuracy(self, x_test, y_test, training=False):\n",
    "        return self.sess.run(self.accuracy,\n",
    "                             feed_dict={self.X: x_test,\n",
    "                                        self.Y: y_test, self.training: training})\n",
    "\n",
    "    def train(self, x_data, y_data, training=True):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
    "            self.X: x_data, self.Y: y_data, self.training: training})\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "\n",
    "models = []\n",
    "num_models = 7\n",
    "for m in range(num_models):\n",
    "    models.append(Model(sess, \"model\" + str(m)))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Learning Started!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. train our ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost_list = np.zeros(len(models))\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "\n",
    "        # train each model\n",
    "        for m_idx, m in enumerate(models):\n",
    "            c, _ = m.train(batch_xs, batch_ys)\n",
    "            avg_cost_list[m_idx] += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', avg_cost_list)\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "test_size = len(mnist.test.labels)\n",
    "predictions = np.zeros(test_size * 10).reshape(test_size, 10)\n",
    "for m_idx, m in enumerate(models):\n",
    "    print(m_idx, 'Accuracy:', m.get_accuracy(\n",
    "        mnist.test.images, mnist.test.labels))\n",
    "    p = m.predict(mnist.test.images)\n",
    "    predictions += p\n",
    "\n",
    "ensemble_correct_prediction = tf.equal(\n",
    "    tf.argmax(predictions, 1), tf.argmax(mnist.test.labels, 1))\n",
    "ensemble_accuracy = tf.reduce_mean(\n",
    "    tf.cast(ensemble_correct_prediction, tf.float32))\n",
    "print('Ensemble accuracy:', sess.run(ensemble_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training result 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Learning Started!\n",
    "Epoch: 0001 cost = [ 0.8285886   0.7736028   0.7857488   0.75940615  0.79814789  0.78667722\n",
    "  0.80067089]\n",
    "Epoch: 0002 cost = [ 0.29876267  0.29312797  0.28643643  0.29918091  0.29994753  0.28521119\n",
    "  0.29203279]\n",
    "Epoch: 0003 cost = [ 0.23014378  0.23366693  0.22784479  0.24353373  0.2370689   0.22865331\n",
    "  0.22992973]\n",
    "Epoch: 0004 cost = [ 0.20278791  0.20509444  0.19784418  0.2094885   0.20768992  0.20207432\n",
    "  0.20021661]\n",
    "Epoch: 0005 cost = [ 0.18334771  0.18573112  0.18400545  0.19082383  0.18628724  0.18291346\n",
    "  0.18421995]\n",
    "Epoch: 0006 cost = [ 0.17065732  0.17457147  0.17230677  0.17679305  0.17644136  0.17437257\n",
    "  0.17084923]\n",
    "Epoch: 0007 cost = [ 0.16017703  0.16466835  0.16185024  0.1692534   0.16537071  0.16400755\n",
    "  0.15925765]\n",
    "Epoch: 0008 cost = [ 0.16058975  0.16071422  0.15743243  0.15889423  0.15913958  0.15940014\n",
    "  0.1582038 ]\n",
    "Epoch: 0009 cost = [ 0.1507076   0.15051623  0.15180255  0.1544444   0.15662055  0.1518818\n",
    "  0.15450658]\n",
    "Epoch: 0010 cost = [ 0.14310655  0.15382333  0.14273362  0.14761922  0.15230439  0.1551467\n",
    "  0.14623267]\n",
    "Epoch: 0011 cost = [ 0.14428991  0.14660035  0.14505644  0.14935583  0.1460829   0.14696486\n",
    "  0.14405732]\n",
    "Epoch: 0012 cost = [ 0.14016805  0.14399414  0.14186701  0.14143713  0.13962515  0.14726369\n",
    "  0.14257362]\n",
    "Epoch: 0013 cost = [ 0.14083112  0.13810326  0.13711051  0.14152663  0.14216629  0.13932477\n",
    "  0.13818365]\n",
    "Epoch: 0014 cost = [ 0.13783987  0.13700243  0.13507878  0.13790451  0.13980047  0.13975731\n",
    "  0.13374982]\n",
    "Epoch: 0015 cost = [ 0.13302495  0.13308863  0.13490895  0.13805266  0.13715017  0.13733935\n",
    "  0.13263847]\n",
    "Epoch: 0016 cost = [ 0.13662738  0.13232288  0.13476929  0.13810129  0.13736914  0.13784942\n",
    "  0.1357136 ]\n",
    "Epoch: 0017 cost = [ 0.13206882  0.13110494  0.13224021  0.13533757  0.13055664  0.13765583\n",
    "  0.13062567]\n",
    "Epoch: 0018 cost = [ 0.1296537   0.13087357  0.13160314  0.13508857  0.13237516  0.13556652\n",
    "  0.13377178]\n",
    "Epoch: 0019 cost = [ 0.13263026  0.12800627  0.12662523  0.12929243  0.13390452  0.131273\n",
    "  0.131616  ]\n",
    "Epoch: 0020 cost = [ 0.12875591  0.12947235  0.12952766  0.13245394  0.13097352  0.13090216\n",
    "  0.12515859]\n",
    "Learning Finished!\n",
    "0 Accuracy: 0.9896\n",
    "1 Accuracy: 0.9906\n",
    "2 Accuracy: 0.9904\n",
    "3 Accuracy: 0.9903\n",
    "4 Accuracy: 0.9895\n",
    "5 Accuracy: 0.9894\n",
    "6 Accuracy: 0.9894\n",
    "Ensemble accuracy: 0.9908\n",
    "\n",
    "Process finished with exit code 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training result 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/home/cine/anaconda3/bin/python /home/cine/PycharmProjects/CNN_MNIST/ensemble.py\n",
    "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\n",
    "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\n",
    "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\n",
    "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\n",
    "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\n",
    "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
    "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
    "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
    "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
    "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
    "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
    "I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \n",
    "name: GeForce GTX 1080\n",
    "major: 6 minor: 1 memoryClockRate (GHz) 1.898\n",
    "pciBusID 0000:01:00.0\n",
    "Total memory: 7.91GiB\n",
    "Free memory: 7.08GiB\n",
    "I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \n",
    "I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \n",
    "I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\n",
    "Learning Started!\n",
    "Epoch: 0001 cost = [ 0.83047655  0.77355436  0.78631724  0.76047829  0.79808162  0.78900232\n",
    "  0.80444025]\n",
    "Epoch: 0002 cost = [ 0.29044883  0.29349009  0.28415209  0.30511432  0.29380412  0.291963\n",
    "  0.30093969]\n",
    "Epoch: 0003 cost = [ 0.22927809  0.2333655   0.22727925  0.24126358  0.23425651  0.22951297\n",
    "  0.23469908]\n",
    "Epoch: 0004 cost = [ 0.19967717  0.19799492  0.19886177  0.21057255  0.20531667  0.19882518\n",
    "  0.20526784]\n",
    "Epoch: 0005 cost = [ 0.18194842  0.18384478  0.18303141  0.18926625  0.18769689  0.18053432\n",
    "  0.18367032]\n",
    "Epoch: 0006 cost = [ 0.1697628   0.17170594  0.16899526  0.17634839  0.17712699  0.17743356\n",
    "  0.17552089]\n",
    "Epoch: 0007 cost = [ 0.15931895  0.16245569  0.16304636  0.17365431  0.16218049  0.16408003\n",
    "  0.16307671]\n",
    "Epoch: 0008 cost = [ 0.15601101  0.15762019  0.16068577  0.15967464  0.16041245  0.1603231\n",
    "  0.15589744]\n",
    "Epoch: 0009 cost = [ 0.15027691  0.1523215   0.15514017  0.15566602  0.15634622  0.1526949\n",
    "  0.15189681]\n",
    "Epoch: 0010 cost = [ 0.15180895  0.14623143  0.1476934   0.14954521  0.15292802  0.14985852\n",
    "  0.14636758]\n",
    "Epoch: 0011 cost = [ 0.14461594  0.14300818  0.14276493  0.14791104  0.14803213  0.14838753\n",
    "  0.14392576]\n",
    "Epoch: 0012 cost = [ 0.14331938  0.14650698  0.14364925  0.14739382  0.14515571  0.1436125\n",
    "  0.14076496]\n",
    "Epoch: 0013 cost = [ 0.138173    0.14032773  0.136132    0.13803601  0.14494504  0.13717389\n",
    "  0.1355785 ]\n",
    "Epoch: 0014 cost = [ 0.13638169  0.13852525  0.13734646  0.13546502  0.13478948  0.13970664\n",
    "  0.13757044]\n",
    "Epoch: 0015 cost = [ 0.13387798  0.13417005  0.137983    0.1342857   0.1365686   0.13471815\n",
    "  0.1334124 ]\n",
    "Epoch: 0016 cost = [ 0.13254187  0.13100623  0.13410034  0.13301066  0.13512878  0.13753826\n",
    "  0.13152365]\n",
    "Epoch: 0017 cost = [ 0.13427727  0.13027125  0.13186019  0.132072    0.13242968  0.13134369\n",
    "  0.13102028]\n",
    "Epoch: 0018 cost = [ 0.13095213  0.13152373  0.12951459  0.13151891  0.12841374  0.13113056\n",
    "  0.12526906]\n",
    "Epoch: 0019 cost = [ 0.12722736  0.1289917   0.13149611  0.12912504  0.12866268  0.13212123\n",
    "  0.13269841]\n",
    "Epoch: 0020 cost = [ 0.12603178  0.13017603  0.12472516  0.13023419  0.13013125  0.13106258\n",
    "  0.12984498]\n",
    "Learning Finished!\n",
    "0 Accuracy: 0.9902\n",
    "1 Accuracy: 0.9908\n",
    "2 Accuracy: 0.9895\n",
    "3 Accuracy: 0.9907\n",
    "4 Accuracy: 0.991\n",
    "5 Accuracy: 0.9899\n",
    "6 Accuracy: 0.9896\n",
    "Ensemble accuracy: 0.9918\n",
    "\n",
    "Process finished with exit code 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the result of trainging with dropout between the conv. layers\n",
    "### Training result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0 Accuracy: 0.9902\n",
    "1 Accuracy: 0.9908\n",
    "2 Accuracy: 0.9895\n",
    "3 Accuracy: 0.9907\n",
    "4 Accuracy: 0.991\n",
    "5 Accuracy: 0.9899\n",
    "6 Accuracy: 0.9896\n",
    "Ensemble accuracy: 0.9918\n",
    "    \n",
    "Learning Finished!\n",
    "0 Accuracy: 0.9896\n",
    "1 Accuracy: 0.9906\n",
    "2 Accuracy: 0.9904\n",
    "3 Accuracy: 0.9903\n",
    "4 Accuracy: 0.9895\n",
    "5 Accuracy: 0.9894\n",
    "6 Accuracy: 0.9894\n",
    "Ensemble accuracy: 0.9908"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training result (without)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Learning Finished!\n",
    "0 Accuracy: 0.9948\n",
    "1 Accuracy: 0.994\n",
    "2 Accuracy: 0.9928\n",
    "3 Accuracy: 0.994\n",
    "4 Accuracy: 0.9947\n",
    "5 Accuracy: 0.995\n",
    "6 Accuracy: 0.9941\n",
    "Ensemble accuracy: 0.9953\n",
    "    \n",
    "Learning Finished!\n",
    "0 Accuracy: 0.9952\n",
    "1 Accuracy: 0.9944\n",
    "2 Accuracy: 0.9937\n",
    "3 Accuracy: 0.9942\n",
    "4 Accuracy: 0.9939\n",
    "5 Accuracy: 0.9955\n",
    "6 Accuracy: 0.9945\n",
    "Ensemble accuracy: 0.9956"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Without dropout between the convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 20\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        self._build_net()\n",
    "\n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            # dropout (keep_prob) rate  0.7~0.5 on training, but should be 1\n",
    "            # for testing\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "\n",
    "            # input place holders\n",
    "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "            # img 28x28x1 (black/white), Input Layer\n",
    "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "            # Convolutional Layer #1\n",
    "            conv1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3, 3],\n",
    "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
    "            # Pooling Layer #1\n",
    "            pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
    "                                            padding=\"SAME\", strides=2)\n",
    "            # dropout1 = tf.layers.dropout(inputs=pool1,\n",
    "            #                              rate=0.7, training=self.training)\n",
    "\n",
    "            # Convolutional Layer #2 and Pooling Layer #2\n",
    "            conv2 = tf.layers.conv2d(inputs=pool1, filters=64, kernel_size=[3, 3],\n",
    "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
    "            pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
    "                                            padding=\"SAME\", strides=2)\n",
    "            # dropout2 = tf.layers.dropout(inputs=pool2,\n",
    "            #                              rate=0.7, training=self.training)\n",
    "\n",
    "            # Convolutional Layer #2 and Pooling Layer #2\n",
    "            conv3 = tf.layers.conv2d(inputs=pool2, filters=128, kernel_size=[3, 3],\n",
    "                                     padding=\"same\", activation=tf.nn.relu)\n",
    "            pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2],\n",
    "                                            padding=\"same\", strides=2)\n",
    "            dropout3 = tf.layers.dropout(inputs=pool3,\n",
    "                                         rate=0.7, training=self.training)\n",
    "\n",
    "            # Dense Layer with Relu\n",
    "            flat = tf.reshape(dropout3, [-1, 128 * 4 * 4])\n",
    "            dense4 = tf.layers.dense(inputs=flat,\n",
    "                                     units=625, activation=tf.nn.relu)\n",
    "            dropout4 = tf.layers.dropout(inputs=dense4,\n",
    "                                         rate=0.5, training=self.training)\n",
    "\n",
    "            # Logits (no activation) Layer: L5 Final FC 625 inputs -> 10 outputs\n",
    "            self.logits = tf.layers.dense(inputs=dropout4, units=10)\n",
    "\n",
    "        # define cost/loss & optimizer\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=self.logits, labels=self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=learning_rate).minimize(self.cost)\n",
    "\n",
    "        correct_prediction = tf.equal(\n",
    "            tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def predict(self, x_test, training=False):\n",
    "        return self.sess.run(self.logits,\n",
    "                             feed_dict={self.X: x_test, self.training: training})\n",
    "\n",
    "    def get_accuracy(self, x_test, y_test, training=False):\n",
    "        return self.sess.run(self.accuracy,\n",
    "                             feed_dict={self.X: x_test,\n",
    "                                        self.Y: y_test, self.training: training})\n",
    "\n",
    "    def train(self, x_data, y_data, training=True):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
    "            self.X: x_data, self.Y: y_data, self.training: training})\n",
    "\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "\n",
    "models = []\n",
    "num_models = 7\n",
    "for m in range(num_models):\n",
    "    models.append(Model(sess, \"model\" + str(m)))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Learning Started!')\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost_list = np.zeros(len(models))\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "\n",
    "        # train each model\n",
    "        for m_idx, m in enumerate(models):# -*- coding: utf-8 -*-\n",
    "# __author__ = \"CHG\"\n",
    "# __createTime__ = '5/5/17'\n",
    "# Email: kwchenghong@gmail.com\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "\n",
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 20\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        self._build_net()\n",
    "\n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            # dropout (keep_prob) rate  0.7~0.5 on training, but should be 1\n",
    "            # for testing\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "\n",
    "            # input place holders\n",
    "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "            # img 28x28x1 (black/white), Input Layer\n",
    "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "            # Convolutional Layer #1\n",
    "            conv1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3, 3],\n",
    "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
    "            # Pooling Layer #1\n",
    "            pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
    "                                            padding=\"SAME\", strides=2)\n",
    "            # dropout1 = tf.layers.dropout(inputs=pool1,\n",
    "            #                              rate=0.7, training=self.training)\n",
    "\n",
    "            # Convolutional Layer #2 and Pooling Layer #2\n",
    "            conv2 = tf.layers.conv2d(inputs=pool1, filters=64, kernel_size=[3, 3],\n",
    "                                     padding=\"SAME\", activation=tf.nn.relu)\n",
    "            pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
    "                                            padding=\"SAME\", strides=2)\n",
    "            # dropout2 = tf.layers.dropout(inputs=pool2,\n",
    "            #                              rate=0.7, training=self.training)\n",
    "\n",
    "            # Convolutional Layer #2 and Pooling Layer #2\n",
    "            conv3 = tf.layers.conv2d(inputs=pool2, filters=128, kernel_size=[3, 3],\n",
    "                                     padding=\"same\", activation=tf.nn.relu)\n",
    "            pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2],\n",
    "                                            padding=\"same\", strides=2)\n",
    "            dropout3 = tf.layers.dropout(inputs=pool3,\n",
    "                                         rate=0.7, training=self.training)\n",
    "\n",
    "            # Dense Layer with Relu\n",
    "            flat = tf.reshape(dropout3, [-1, 128 * 4 * 4])\n",
    "            dense4 = tf.layers.dense(inputs=flat,\n",
    "                                     units=625, activation=tf.nn.relu)\n",
    "            dropout4 = tf.layers.dropout(inputs=dense4,\n",
    "                                         rate=0.5, training=self.training)\n",
    "\n",
    "            # Logits (no activation) Layer: L5 Final FC 625 inputs -> 10 outputs\n",
    "            self.logits = tf.layers.dense(inputs=dropout4, units=10)\n",
    "\n",
    "        # define cost/loss & optimizer\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=self.logits, labels=self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=learning_rate).minimize(self.cost)\n",
    "\n",
    "        correct_prediction = tf.equal(\n",
    "            tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def predict(self, x_test, training=False):\n",
    "        return self.sess.run(self.logits,\n",
    "                             feed_dict={self.X: x_test, self.training: training})\n",
    "\n",
    "    def get_accuracy(self, x_test, y_test, training=False):\n",
    "        return self.sess.run(self.accuracy,\n",
    "                             feed_dict={self.X: x_test,\n",
    "                                        self.Y: y_test, self.training: training})\n",
    "\n",
    "    def train(self, x_data, y_data, training=True):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
    "            self.X: x_data, self.Y: y_data, self.training: training})\n",
    "\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "\n",
    "models = []\n",
    "num_models = 7\n",
    "for m in range(num_models):\n",
    "    models.append(Model(sess, \"model\" + str(m)))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Learning Started!')\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost_list = np.zeros(len(models))\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "\n",
    "        # train each model\n",
    "        for m_idx, m in enumerate(models):\n",
    "            c, _ = m.train(batch_xs, batch_ys)\n",
    "            avg_cost_list[m_idx] += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', avg_cost_list)\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "test_size = len(mnist.test.labels)\n",
    "predictions = np.zeros(test_size * 10).reshape(test_size, 10)\n",
    "for m_idx, m in enumerate(models):\n",
    "    print(m_idx, 'Accuracy:', m.get_accuracy(\n",
    "        mnist.test.images, mnist.test.labels))\n",
    "    p = m.predict(mnist.test.images)\n",
    "    predictions += p\n",
    "\n",
    "ensemble_correct_prediction = tf.equal(\n",
    "    tf.argmax(predictions, 1), tf.argmax(mnist.test.labels, 1))\n",
    "ensemble_accuracy = tf.reduce_mean(\n",
    "    tf.cast(ensemble_correct_prediction, tf.float32))\n",
    "print('Ensemble accuracy:', sess.run(ensemble_accuracy))\n",
    "\n",
    "            c, _ = m.train(batch_xs, batch_ys)\n",
    "            avg_cost_list[m_idx] += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', avg_cost_list)\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "test_size = len(mnist.test.labels)\n",
    "predictions = np.zeros(test_size * 10).reshape(test_size, 10)\n",
    "for m_idx, m in enumerate(models):\n",
    "    print(m_idx, 'Accuracy:', m.get_accuracy(\n",
    "        mnist.test.images, mnist.test.labels))\n",
    "    p = m.predict(mnist.test.images)\n",
    "    predictions += p\n",
    "\n",
    "ensemble_correct_prediction = tf.equal(\n",
    "    tf.argmax(predictions, 1), tf.argmax(mnist.test.labels, 1))\n",
    "ensemble_accuracy = tf.reduce_mean(\n",
    "    tf.cast(ensemble_correct_prediction, tf.float32))\n",
    "print('Ensemble accuracy:', sess.run(ensemble_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training result 1(without)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/home/cine/anaconda3/bin/python /home/cine/PycharmProjects/CNN_MNIST/ensemble2.py\n",
    "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\n",
    "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\n",
    "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\n",
    "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\n",
    "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\n",
    "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
    "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
    "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
    "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
    "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
    "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
    "I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \n",
    "name: GeForce GTX 1080\n",
    "major: 6 minor: 1 memoryClockRate (GHz) 1.898\n",
    "pciBusID 0000:01:00.0\n",
    "Total memory: 7.91GiB\n",
    "Free memory: 7.09GiB\n",
    "I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \n",
    "I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \n",
    "I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\n",
    "Learning Started!\n",
    "Epoch: 0001 cost = [ 0.27680884  0.28473268  0.29844935  0.28272435  0.28920459  0.29054749\n",
    "  0.2887564 ]\n",
    "Epoch: 0002 cost = [ 0.09735898  0.09161068  0.09377506  0.09207193  0.09295438  0.09206543\n",
    "  0.09443576]\n",
    "Epoch: 0003 cost = [ 0.07206015  0.06818733  0.07169108  0.06935435  0.06900203  0.07044479\n",
    "  0.07124836]\n",
    "Epoch: 0004 cost = [ 0.06149847  0.05680746  0.06076545  0.06161918  0.05839696  0.0576337\n",
    "  0.0590065 ]\n",
    "Epoch: 0005 cost = [ 0.05381385  0.05125328  0.05252606  0.05274087  0.05048139  0.05205292\n",
    "  0.0522524 ]\n",
    "Epoch: 0006 cost = [ 0.0473631   0.04484748  0.04715837  0.04439492  0.04574615  0.04498552\n",
    "  0.04781991]\n",
    "Epoch: 0007 cost = [ 0.0446623   0.04227922  0.04209529  0.04279164  0.04226583  0.04147751\n",
    "  0.04379641]\n",
    "Epoch: 0008 cost = [ 0.0420294   0.03818532  0.03937593  0.0382924   0.03890409  0.03651301\n",
    "  0.03834822]\n",
    "Epoch: 0009 cost = [ 0.03697141  0.03676942  0.03796514  0.03641365  0.03713465  0.03345095\n",
    "  0.03604359]\n",
    "Epoch: 0010 cost = [ 0.03488226  0.03521734  0.03289332  0.03632225  0.0323164   0.03282443\n",
    "  0.03401624]\n",
    "Epoch: 0011 cost = [ 0.03125854  0.03214217  0.03146074  0.03352601  0.03328456  0.03227083\n",
    "  0.03287639]\n",
    "Epoch: 0012 cost = [ 0.02968449  0.03026564  0.0322317   0.02960546  0.02803696  0.02834099\n",
    "  0.03111151]\n",
    "Epoch: 0013 cost = [ 0.02974757  0.02791822  0.02769843  0.02910324  0.02782573  0.0281397\n",
    "  0.02740344]\n",
    "Epoch: 0014 cost = [ 0.02940068  0.02809145  0.02745237  0.02796813  0.02638819  0.02450916\n",
    "  0.02707688]\n",
    "Epoch: 0015 cost = [ 0.02639095  0.02558048  0.02610494  0.02528079  0.02496747  0.02611854\n",
    "  0.02757929]\n",
    "Epoch: 0016 cost = [ 0.02452684  0.02454993  0.02435415  0.02746548  0.02591348  0.02430854\n",
    "  0.0252154 ]\n",
    "Epoch: 0017 cost = [ 0.02636152  0.02259956  0.02403106  0.02418848  0.02346992  0.0233809\n",
    "  0.02408849]\n",
    "Epoch: 0018 cost = [ 0.02359937  0.0240713   0.0254393   0.02333885  0.02135288  0.02136151\n",
    "  0.02308267]\n",
    "Epoch: 0019 cost = [ 0.02268584  0.02340459  0.02195712  0.02281069  0.02105249  0.0233533\n",
    "  0.02270263]\n",
    "Epoch: 0020 cost = [ 0.02245908  0.02067757  0.02091201  0.02039999  0.0210384   0.02052974\n",
    "  0.02299357]\n",
    "Learning Finished!\n",
    "0 Accuracy: 0.9952\n",
    "1 Accuracy: 0.9944\n",
    "2 Accuracy: 0.9937\n",
    "3 Accuracy: 0.9942\n",
    "4 Accuracy: 0.9939\n",
    "5 Accuracy: 0.9955\n",
    "6 Accuracy: 0.9945\n",
    "Ensemble accuracy: 0.9956\n",
    "\n",
    "Process finished with exit code 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training result 2(without)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/home/cine/anaconda3/bin/python /home/cine/PycharmProjects/CNN_MNIST/ensemble2.py\n",
    "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\n",
    "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\n",
    "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\n",
    "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\n",
    "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\n",
    "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
    "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
    "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
    "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
    "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
    "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
    "I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \n",
    "name: GeForce GTX 1080\n",
    "major: 6 minor: 1 memoryClockRate (GHz) 1.898\n",
    "pciBusID 0000:01:00.0\n",
    "Total memory: 7.91GiB\n",
    "Free memory: 6.92GiB\n",
    "I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \n",
    "I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \n",
    "I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)\n",
    "Learning Started!\n",
    "Epoch: 0001 cost = [ 0.27896288  0.28449352  0.29841569  0.2835605   0.28947163  0.28952805\n",
    "  0.28778763]\n",
    "Epoch: 0002 cost = [ 0.09733404  0.09115166  0.09258227  0.09402824  0.09172092  0.09266431\n",
    "  0.09220581]\n",
    "Epoch: 0003 cost = [ 0.07203782  0.07086627  0.0721186   0.0691958   0.07018349  0.06762542\n",
    "  0.06911754]\n",
    "Epoch: 0004 cost = [ 0.05874403  0.06109618  0.06024651  0.06041027  0.0583746   0.05944427\n",
    "  0.06089767]\n",
    "Epoch: 0005 cost = [ 0.05257655  0.0521298   0.05208349  0.05196292  0.04994644  0.04998246\n",
    "  0.04959187]\n",
    "Epoch: 0006 cost = [ 0.04893311  0.04803214  0.04703087  0.0469461   0.04695686  0.04476551\n",
    "  0.0454702 ]\n",
    "Epoch: 0007 cost = [ 0.04417387  0.04193157  0.04220696  0.041465    0.04144732  0.04134626\n",
    "  0.0400673 ]\n",
    "Epoch: 0008 cost = [ 0.03962938  0.03990052  0.03950938  0.04098858  0.03755157  0.03760113\n",
    "  0.0402993 ]\n",
    "Epoch: 0009 cost = [ 0.03705844  0.03853027  0.03734854  0.03718832  0.03607053  0.03682194\n",
    "  0.03581756]\n",
    "Epoch: 0010 cost = [ 0.03406331  0.03181378  0.03280855  0.03528593  0.03234821  0.03406168\n",
    "  0.03532582]\n",
    "Epoch: 0011 cost = [ 0.03138393  0.03134186  0.03308107  0.03271678  0.03154335  0.03052479\n",
    "  0.0327291 ]\n",
    "Epoch: 0012 cost = [ 0.03241862  0.028882    0.02906032  0.03033578  0.02943393  0.02843441\n",
    "  0.0293292 ]\n",
    "Epoch: 0013 cost = [ 0.03093915  0.02937761  0.0286764   0.02788935  0.02761049  0.02920519\n",
    "  0.02787066]\n",
    "Epoch: 0014 cost = [ 0.02992337  0.02730394  0.02601471  0.02775679  0.02754987  0.02814648\n",
    "  0.02782688]\n",
    "Epoch: 0015 cost = [ 0.02583008  0.02634076  0.02666942  0.02722986  0.02790946  0.02357761\n",
    "  0.02762701]\n",
    "Epoch: 0016 cost = [ 0.0240907   0.02504775  0.02584813  0.0260319   0.02144041  0.02669045\n",
    "  0.02396525]\n",
    "Epoch: 0017 cost = [ 0.02595522  0.02481141  0.02447678  0.02359887  0.02335667  0.02383656\n",
    "  0.02263436]\n",
    "Epoch: 0018 cost = [ 0.02362997  0.02075641  0.02376856  0.02258869  0.02292579  0.02329117\n",
    "  0.02282054]\n",
    "Epoch: 0019 cost = [ 0.02402067  0.02285908  0.02175709  0.022044    0.02130014  0.02163807\n",
    "  0.02321238]\n",
    "Epoch: 0020 cost = [ 0.02004196  0.02110491  0.02180612  0.0213354   0.0217759   0.02016811\n",
    "  0.0228333 ]\n",
    "Learning Finished!\n",
    "0 Accuracy: 0.9948\n",
    "1 Accuracy: 0.994\n",
    "2 Accuracy: 0.9928\n",
    "3 Accuracy: 0.994\n",
    "4 Accuracy: 0.9947\n",
    "5 Accuracy: 0.995\n",
    "6 Accuracy: 0.9941\n",
    "Ensemble accuracy: 0.9953\n",
    "\n",
    "Process finished with exit code 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

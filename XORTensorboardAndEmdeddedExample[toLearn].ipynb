{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.716823 [array([[ 0.80257797,  0.67862517],\n",
      "       [-1.21711969, -0.30515376]], dtype=float32), array([[ 1.70787132],\n",
      "       [ 0.34588468]], dtype=float32)]\n",
      "100 0.713476 [array([[ 0.78934962,  0.67951226],\n",
      "       [-1.20213175, -0.3039225 ]], dtype=float32), array([[ 1.72049773],\n",
      "       [ 0.35917631]], dtype=float32)]\n",
      "200 0.711481 [array([[ 0.77402139,  0.67987025],\n",
      "       [-1.18934059, -0.30310664]], dtype=float32), array([[ 1.72628391],\n",
      "       [ 0.36835146]], dtype=float32)]\n",
      "300 0.710122 [array([[ 0.75750601,  0.67986482],\n",
      "       [-1.1781534 , -0.30259413]], dtype=float32), array([[ 1.72757244],\n",
      "       [ 0.37475097]], dtype=float32)]\n",
      "400 0.709076 [array([[ 0.74042237,  0.67961764],\n",
      "       [-1.16814351, -0.30229974]], dtype=float32), array([[ 1.72595263],\n",
      "       [ 0.37928456]], dtype=float32)]\n",
      "500 0.708195 [array([[ 0.723185  ,  0.67921495],\n",
      "       [-1.15900898, -0.30216199]], dtype=float32), array([[ 1.72248483],\n",
      "       [ 0.38256407]], dtype=float32)]\n",
      "600 0.707413 [array([[ 0.70606822,  0.67871553],\n",
      "       [-1.15053904, -0.30213758]], dtype=float32), array([[ 1.71787131],\n",
      "       [ 0.38499841]], dtype=float32)]\n",
      "700 0.706698 [array([[ 0.68924922,  0.67815953],\n",
      "       [-1.14258552, -0.30219713]], dtype=float32), array([[ 1.71257198],\n",
      "       [ 0.3868604 ]], dtype=float32)]\n",
      "800 0.706035 [array([[ 0.67284161,  0.67757356],\n",
      "       [-1.13504505, -0.30232048]], dtype=float32), array([[ 1.70688701],\n",
      "       [ 0.38833174]], dtype=float32)]\n",
      "900 0.705417 [array([[ 0.65691531,  0.67697513],\n",
      "       [-1.12784243, -0.30249405]], dtype=float32), array([[ 1.70101047],\n",
      "       [ 0.38953367]], dtype=float32)]\n",
      "1000 0.704838 [array([[ 0.6415112 ,  0.67637622],\n",
      "       [-1.12092531, -0.30270863]], dtype=float32), array([[ 1.69506645],\n",
      "       [ 0.3905468 ]], dtype=float32)]\n",
      "1100 0.704294 [array([[ 0.62665045,  0.67578417],\n",
      "       [-1.114254  , -0.30295801]], dtype=float32), array([[ 1.68913245],\n",
      "       [ 0.39142516]], dtype=float32)]\n",
      "1200 0.703783 [array([[ 0.61234117,  0.67520428],\n",
      "       [-1.10779941, -0.30323812]], dtype=float32), array([[ 1.68325698],\n",
      "       [ 0.39220479]], dtype=float32)]\n",
      "1300 0.703303 [array([[ 0.59858316,  0.67463863],\n",
      "       [-1.10153854, -0.30354619]], dtype=float32), array([[ 1.67746878],\n",
      "       [ 0.39291009]], dtype=float32)]\n",
      "1400 0.702852 [array([[ 0.58536988,  0.67408985],\n",
      "       [-1.09545386, -0.30388016]], dtype=float32), array([[ 1.67178321],\n",
      "       [ 0.3935577 ]], dtype=float32)]\n",
      "1500 0.702428 [array([[ 0.57269126,  0.67355835],\n",
      "       [-1.08953047, -0.3042388 ]], dtype=float32), array([[ 1.66620839],\n",
      "       [ 0.39415884]], dtype=float32)]\n",
      "1600 0.702028 [array([[ 0.56053466,  0.67304456],\n",
      "       [-1.08375669, -0.30462122]], dtype=float32), array([[ 1.66074669],\n",
      "       [ 0.39472127]], dtype=float32)]\n",
      "1700 0.701652 [array([[ 0.54888606,  0.67254871],\n",
      "       [-1.07812238, -0.30502665]], dtype=float32), array([[ 1.65539777],\n",
      "       [ 0.39525062]], dtype=float32)]\n",
      "1800 0.701297 [array([[ 0.53773081,  0.67207068],\n",
      "       [-1.07261884, -0.3054547 ]], dtype=float32), array([[ 1.65015852],\n",
      "       [ 0.39575085]], dtype=float32)]\n",
      "1900 0.700963 [array([[ 0.52705294,  0.67161018],\n",
      "       [-1.06723881, -0.30590498]], dtype=float32), array([[ 1.64502621],\n",
      "       [ 0.39622501]], dtype=float32)]\n",
      "2000 0.700647 [array([[ 0.516837  ,  0.67116684],\n",
      "       [-1.06197548, -0.30637717]], dtype=float32), array([[ 1.63999629],\n",
      "       [ 0.39667544]], dtype=float32)]\n",
      "2100 0.700349 [array([[ 0.50706708,  0.67074013],\n",
      "       [-1.0568229 , -0.30687097]], dtype=float32), array([[ 1.63506436],\n",
      "       [ 0.397104  ]], dtype=float32)]\n",
      "2200 0.700068 [array([[ 0.49772796,  0.67032969],\n",
      "       [-1.05177653, -0.3073861 ]], dtype=float32), array([[ 1.6302259 ],\n",
      "       [ 0.39751223]], dtype=float32)]\n",
      "2300 0.699802 [array([[ 0.48880401,  0.66993558],\n",
      "       [-1.04683125, -0.30792245]], dtype=float32), array([[ 1.62547708],\n",
      "       [ 0.39790145]], dtype=float32)]\n",
      "2400 0.699549 [array([[ 0.48028037,  0.66955656],\n",
      "       [-1.04198313, -0.30847979]], dtype=float32), array([[ 1.62081349],\n",
      "       [ 0.39827284]], dtype=float32)]\n",
      "2500 0.699311 [array([[ 0.4721424 ,  0.66919273],\n",
      "       [-1.03722811, -0.30905789]], dtype=float32), array([[ 1.61623132],\n",
      "       [ 0.39862758]], dtype=float32)]\n",
      "2600 0.699084 [array([[ 0.46437576,  0.66884327],\n",
      "       [-1.03256333, -0.30965656]], dtype=float32), array([[ 1.61172676],\n",
      "       [ 0.39896661]], dtype=float32)]\n",
      "2700 0.698869 [array([[ 0.45696664,  0.66850835],\n",
      "       [-1.02798557, -0.31027558]], dtype=float32), array([[ 1.60729671],\n",
      "       [ 0.39929092]], dtype=float32)]\n",
      "2800 0.698665 [array([[ 0.4499017 ,  0.6681869 ],\n",
      "       [-1.0234921 , -0.31091475]], dtype=float32), array([[ 1.60293806],\n",
      "       [ 0.39960128]], dtype=float32)]\n",
      "2900 0.698471 [array([[ 0.44316798,  0.66787869],\n",
      "       [-1.01908076, -0.31157383]], dtype=float32), array([[ 1.59864783],\n",
      "       [ 0.3998988 ]], dtype=float32)]\n",
      "3000 0.698286 [array([[ 0.43675295,  0.66758358],\n",
      "       [-1.01474893, -0.31225273]], dtype=float32), array([[ 1.59442317],\n",
      "       [ 0.40018415]], dtype=float32)]\n",
      "3100 0.69811 [array([[ 0.43064445,  0.6673013 ],\n",
      "       [-1.01049459, -0.31295106]], dtype=float32), array([[ 1.59026182],\n",
      "       [ 0.40045819]], dtype=float32)]\n",
      "3200 0.697942 [array([[ 0.42483103,  0.66703123],\n",
      "       [-1.00631618, -0.31366885]], dtype=float32), array([[ 1.58616161],\n",
      "       [ 0.4007217 ]], dtype=float32)]\n",
      "3300 0.697781 [array([[ 0.41930136,  0.66677308],\n",
      "       [-1.00221229, -0.31440565]], dtype=float32), array([[ 1.58212042],\n",
      "       [ 0.40097544]], dtype=float32)]\n",
      "3400 0.697628 [array([[ 0.41404465,  0.6665265 ],\n",
      "       [-0.99818116, -0.31516147]], dtype=float32), array([[ 1.57813632],\n",
      "       [ 0.40121999]], dtype=float32)]\n",
      "3500 0.697481 [array([[ 0.40905046,  0.66629124],\n",
      "       [-0.99422139, -0.31593597]], dtype=float32), array([[ 1.57420719],\n",
      "       [ 0.40145606]], dtype=float32)]\n",
      "3600 0.69734 [array([[ 0.40430897,  0.66606736],\n",
      "       [-0.99033201, -0.31672898]], dtype=float32), array([[ 1.57033205],\n",
      "       [ 0.40168455]], dtype=float32)]\n",
      "3700 0.697205 [array([[ 0.39981067,  0.6658541 ],\n",
      "       [-0.98651189, -0.31754029]], dtype=float32), array([[ 1.56650853],\n",
      "       [ 0.40190575]], dtype=float32)]\n",
      "3800 0.697076 [array([[ 0.39554623,  0.6656512 ],\n",
      "       [-0.98276013, -0.31836969]], dtype=float32), array([[ 1.56273603],\n",
      "       [ 0.4021205 ]], dtype=float32)]\n",
      "3900 0.696951 [array([[ 0.39150703,  0.66545826],\n",
      "       [-0.97907585, -0.319217  ]], dtype=float32), array([[ 1.55901289],\n",
      "       [ 0.4023293 ]], dtype=float32)]\n",
      "4000 0.696831 [array([[ 0.38768452,  0.66527599],\n",
      "       [-0.9754582 , -0.32008207]], dtype=float32), array([[ 1.55533767],\n",
      "       [ 0.40253285]], dtype=float32)]\n",
      "4100 0.696716 [array([[ 0.38407066,  0.66510314],\n",
      "       [-0.97190678, -0.3209646 ]], dtype=float32), array([[ 1.55170929],\n",
      "       [ 0.40273124]], dtype=float32)]\n",
      "4200 0.696605 [array([[ 0.38065785,  0.66493958],\n",
      "       [-0.96842068, -0.32186443]], dtype=float32), array([[ 1.54812694],\n",
      "       [ 0.40292567]], dtype=float32)]\n",
      "4300 0.696497 [array([[ 0.37743846,  0.6647858 ],\n",
      "       [-0.96499962, -0.32278132]], dtype=float32), array([[ 1.54458952],\n",
      "       [ 0.40311581]], dtype=float32)]\n",
      "4400 0.696394 [array([[ 0.3744055 ,  0.66464049],\n",
      "       [-0.96164298, -0.32371524]], dtype=float32), array([[ 1.54109585],\n",
      "       [ 0.40330267]], dtype=float32)]\n",
      "4500 0.696293 [array([[ 0.37155226,  0.66450489],\n",
      "       [-0.95835024, -0.32466576]], dtype=float32), array([[ 1.53764522],\n",
      "       [ 0.4034867 ]], dtype=float32)]\n",
      "4600 0.696196 [array([[ 0.3688722 ,  0.66437733],\n",
      "       [-0.95512122, -0.32563284]], dtype=float32), array([[ 1.53423715],\n",
      "       [ 0.40366846]], dtype=float32)]\n",
      "4700 0.696102 [array([[ 0.36635917,  0.66425884],\n",
      "       [-0.9519555 , -0.32661635]], dtype=float32), array([[ 1.5308702 ],\n",
      "       [ 0.40384728]], dtype=float32)]\n",
      "4800 0.696011 [array([[ 0.36400717,  0.66414851],\n",
      "       [-0.94885284, -0.32761604]], dtype=float32), array([[ 1.52754402],\n",
      "       [ 0.40402505]], dtype=float32)]\n",
      "4900 0.695923 [array([[ 0.36181065,  0.66404605],\n",
      "       [-0.94581294, -0.32863164]], dtype=float32), array([[ 1.52425826],\n",
      "       [ 0.40420088]], dtype=float32)]\n",
      "5000 0.695836 [array([[ 0.35976422,  0.66395241],\n",
      "       [-0.94283551, -0.32966316]], dtype=float32), array([[ 1.52101147],\n",
      "       [ 0.40437672]], dtype=float32)]\n",
      "5100 0.695753 [array([[ 0.35786247,  0.66386622],\n",
      "       [-0.93992043, -0.33071026]], dtype=float32), array([[ 1.51780307],\n",
      "       [ 0.40455139]], dtype=float32)]\n",
      "5200 0.695671 [array([[ 0.35610065,  0.66378742],\n",
      "       [-0.93706745, -0.33177283]], dtype=float32), array([[ 1.51463366],\n",
      "       [ 0.40472424]], dtype=float32)]\n",
      "5300 0.695592 [array([[ 0.35447398,  0.66371721],\n",
      "       [-0.93427658, -0.33285069]], dtype=float32), array([[ 1.51150155],\n",
      "       [ 0.40489709]], dtype=float32)]\n",
      "5400 0.695514 [array([[ 0.35297796,  0.66365415],\n",
      "       [-0.93154758, -0.33394367]], dtype=float32), array([[ 1.50840652],\n",
      "       [ 0.4050703 ]], dtype=float32)]\n",
      "5500 0.695439 [array([[ 0.35160846,  0.66359824],\n",
      "       [-0.92888051, -0.33505166]], dtype=float32), array([[ 1.50534809],\n",
      "       [ 0.40524614]], dtype=float32)]\n",
      "5600 0.695365 [array([[ 0.3503612 ,  0.66354936],\n",
      "       [-0.92627531, -0.33617443]], dtype=float32), array([[ 1.50232553],\n",
      "       [ 0.40542197]], dtype=float32)]\n",
      "5700 0.695293 [array([[ 0.34923229,  0.66350824],\n",
      "       [-0.92373168, -0.33731186]], dtype=float32), array([[ 1.49933863],\n",
      "       [ 0.40559781]], dtype=float32)]\n",
      "5800 0.695222 [array([[ 0.34821799,  0.6634742 ],\n",
      "       [-0.92124981, -0.33846381]], dtype=float32), array([[ 1.49638677],\n",
      "       [ 0.40577543]], dtype=float32)]\n",
      "5900 0.695153 [array([[ 0.34731477,  0.66344696],\n",
      "       [-0.91882956, -0.3396301 ]], dtype=float32), array([[ 1.49346948],\n",
      "       [ 0.40595424]], dtype=float32)]\n",
      "6000 0.695085 [array([[ 0.34651926,  0.66342646],\n",
      "       [-0.91647094, -0.34081054]], dtype=float32), array([[ 1.49058628],\n",
      "       [ 0.40613484]], dtype=float32)]\n",
      "6100 0.695019 [array([[ 0.34582818,  0.66341263],\n",
      "       [-0.91417426, -0.3420051 ]], dtype=float32), array([[ 1.4877373 ],\n",
      "       [ 0.40631664]], dtype=float32)]\n",
      "6200 0.694953 [array([[ 0.34523854,  0.66340542],\n",
      "       [-0.9119392 , -0.34321353]], dtype=float32), array([[ 1.48492205],\n",
      "       [ 0.40650141]], dtype=float32)]\n",
      "6300 0.694889 [array([[ 0.3447473 ,  0.66340476],\n",
      "       [-0.90976584, -0.34443566]], dtype=float32), array([[ 1.48213983],\n",
      "       [ 0.40668795]], dtype=float32)]\n",
      "6400 0.694826 [array([[ 0.34435168,  0.66341102],\n",
      "       [-0.90765435, -0.34567156]], dtype=float32), array([[ 1.47939003],\n",
      "       [ 0.40687662]], dtype=float32)]\n",
      "6500 0.694764 [array([[ 0.34404901,  0.66342378],\n",
      "       [-0.90560472, -0.34692076]], dtype=float32), array([[ 1.47667265],\n",
      "       [ 0.40706775]], dtype=float32)]\n",
      "6600 0.694703 [array([[ 0.34383678,  0.66344285],\n",
      "       [-0.90361702, -0.34818342]], dtype=float32), array([[ 1.47398806],\n",
      "       [ 0.40726155]], dtype=float32)]\n",
      "6700 0.694643 [array([[ 0.34371254,  0.66346818],\n",
      "       [-0.90169144, -0.34945923]], dtype=float32), array([[ 1.4713347 ],\n",
      "       [ 0.40745825]], dtype=float32)]\n",
      "6800 0.694584 [array([[ 0.34367406,  0.66349977],\n",
      "       [-0.8998279 , -0.35074815]], dtype=float32), array([[ 1.46871281],\n",
      "       [ 0.40765786]], dtype=float32)]\n",
      "6900 0.694525 [array([[ 0.34371904,  0.6635375 ],\n",
      "       [-0.8980267 , -0.35205007]], dtype=float32), array([[ 1.46612263],\n",
      "       [ 0.40786049]], dtype=float32)]\n",
      "7000 0.694467 [array([[ 0.34384549,  0.66358137],\n",
      "       [-0.8962878 , -0.35336474]], dtype=float32), array([[ 1.46356261],\n",
      "       [ 0.40806636]], dtype=float32)]\n",
      "7100 0.69441 [array([[ 0.34405142,  0.66363126],\n",
      "       [-0.89461148, -0.35469207]], dtype=float32), array([[ 1.46103406],\n",
      "       [ 0.40827551]], dtype=float32)]\n",
      "7200 0.694354 [array([[ 0.34433493,  0.66368717],\n",
      "       [-0.89299768, -0.3560321 ]], dtype=float32), array([[ 1.45853531],\n",
      "       [ 0.40848798]], dtype=float32)]\n",
      "7300 0.694298 [array([[ 0.34469405,  0.66374904],\n",
      "       [-0.89144677, -0.35738453]], dtype=float32), array([[ 1.45606709],\n",
      "       [ 0.40870383]], dtype=float32)]\n",
      "7400 0.694242 [array([[ 0.34512743,  0.66381687],\n",
      "       [-0.88995868, -0.35874933]], dtype=float32), array([[ 1.45362854],\n",
      "       [ 0.40892318]], dtype=float32)]\n",
      "7500 0.694187 [array([[ 0.34563342,  0.66389054],\n",
      "       [-0.88853377, -0.36012638]], dtype=float32), array([[ 1.45121992],\n",
      "       [ 0.40914598]], dtype=float32)]\n",
      "7600 0.694133 [array([[ 0.34621042,  0.66397005],\n",
      "       [-0.8871721 , -0.36151552]], dtype=float32), array([[ 1.44884038],\n",
      "       [ 0.40937284]], dtype=float32)]\n",
      "7700 0.694079 [array([[ 0.34685695,  0.66405535],\n",
      "       [-0.88587385, -0.36291665]], dtype=float32), array([[ 1.44649065],\n",
      "       [ 0.40960342]], dtype=float32)]\n",
      "7800 0.694026 [array([[ 0.34757173,  0.66414642],\n",
      "       [-0.88463938, -0.3643297 ]], dtype=float32), array([[ 1.44416916],\n",
      "       [ 0.40983763]], dtype=float32)]\n",
      "7900 0.693972 [array([[ 0.34835348,  0.66424316],\n",
      "       [-0.88346863, -0.36575451]], dtype=float32), array([[ 1.44187772],\n",
      "       [ 0.41007575]], dtype=float32)]\n",
      "8000 0.69392 [array([[ 0.34920087,  0.66434562],\n",
      "       [-0.88236195, -0.36719102]], dtype=float32), array([[ 1.43961418],\n",
      "       [ 0.41031811]], dtype=float32)]\n",
      "8100 0.693867 [array([[ 0.35011283,  0.66445369],\n",
      "       [-0.88131964, -0.36863905]], dtype=float32), array([[ 1.4373796 ],\n",
      "       [ 0.41056421]], dtype=float32)]\n",
      "8200 0.693815 [array([[ 0.35108835,  0.66456735],\n",
      "       [-0.88034183, -0.37009853]], dtype=float32), array([[ 1.43517351],\n",
      "       [ 0.41081434]], dtype=float32)]\n",
      "8300 0.693763 [array([[ 0.3521263 ,  0.66468662],\n",
      "       [-0.8794288 , -0.37156942]], dtype=float32), array([[ 1.43299496],\n",
      "       [ 0.4110688 ]], dtype=float32)]\n",
      "8400 0.693711 [array([[ 0.35322583,  0.66481179],\n",
      "       [-0.87858075, -0.37305167]], dtype=float32), array([[ 1.43084562],\n",
      "       [ 0.41132703]], dtype=float32)]\n",
      "8500 0.693659 [array([[ 0.35438597,  0.6649425 ],\n",
      "       [-0.87779796, -0.37454507]], dtype=float32), array([[ 1.42872381],\n",
      "       [ 0.41158971]], dtype=float32)]\n",
      "8600 0.693608 [array([[ 0.35560578,  0.66507876],\n",
      "       [-0.87708074, -0.37604943]], dtype=float32), array([[ 1.42662942],\n",
      "       [ 0.41185647]], dtype=float32)]\n",
      "8700 0.693556 [array([[ 0.3568849 ,  0.6652205 ],\n",
      "       [-0.87642938, -0.37756485]], dtype=float32), array([[ 1.42456388],\n",
      "       [ 0.41212732]], dtype=float32)]\n",
      "8800 0.693505 [array([[ 0.35822231,  0.66536766],\n",
      "       [-0.87584424, -0.3790912 ]], dtype=float32), array([[ 1.42252553],\n",
      "       [ 0.41240263]], dtype=float32)]\n",
      "8900 0.693453 [array([[ 0.35961741,  0.66552025],\n",
      "       [-0.87532532, -0.38062823]], dtype=float32), array([[ 1.42051435],\n",
      "       [ 0.41268182]], dtype=float32)]\n",
      "9000 0.693402 [array([[ 0.3610695 ,  0.66567826],\n",
      "       [-0.87487322, -0.3821761 ]], dtype=float32), array([[ 1.41853178],\n",
      "       [ 0.41296566]], dtype=float32)]\n",
      "9100 0.693351 [array([[ 0.36257806,  0.66584164],\n",
      "       [-0.87448817, -0.38373449]], dtype=float32), array([[ 1.41657627],\n",
      "       [ 0.41325346]], dtype=float32)]\n",
      "9200 0.693299 [array([[ 0.3641426 ,  0.66601032],\n",
      "       [-0.87417042, -0.38530347]], dtype=float32), array([[ 1.41464782],\n",
      "       [ 0.41354558]], dtype=float32)]\n",
      "9300 0.693248 [array([[ 0.36576259,  0.66618437],\n",
      "       [-0.87392038, -0.38688281]], dtype=float32), array([[ 1.41274738],\n",
      "       [ 0.41384202]], dtype=float32)]\n",
      "9400 0.693197 [array([[ 0.3674376 ,  0.66636372],\n",
      "       [-0.87373835, -0.38847259]], dtype=float32), array([[ 1.41087437],\n",
      "       [ 0.41414246]], dtype=float32)]\n",
      "9500 0.693145 [array([[ 0.36916718,  0.66654849],\n",
      "       [-0.87362474, -0.39007249]], dtype=float32), array([[ 1.40902841],\n",
      "       [ 0.41444749]], dtype=float32)]\n",
      "9600 0.693093 [array([[ 0.37095106,  0.66673905],\n",
      "       [-0.87357992, -0.39168274]], dtype=float32), array([[ 1.40720999],\n",
      "       [ 0.41475636]], dtype=float32)]\n",
      "9700 0.693041 [array([[ 0.37278894,  0.66693491],\n",
      "       [-0.87360424, -0.39330295]], dtype=float32), array([[ 1.40541947],\n",
      "       [ 0.41506979]], dtype=float32)]\n",
      "9800 0.692989 [array([[ 0.37468052,  0.66713601],\n",
      "       [-0.87369806, -0.39493325]], dtype=float32), array([[ 1.40365601],\n",
      "       [ 0.41538721]], dtype=float32)]\n",
      "9900 0.692937 [array([[ 0.37662554,  0.66734236],\n",
      "       [-0.87386179, -0.39657351]], dtype=float32), array([[ 1.40191972],\n",
      "       [ 0.41570872]], dtype=float32)]\n",
      "10000 0.692884 [array([[ 0.37862378,  0.6675539 ],\n",
      "       [-0.87409598, -0.39822349]], dtype=float32), array([[ 1.40021193],\n",
      "       [ 0.41603461]], dtype=float32)]\n",
      "\n",
      "Hypothesis:  [[ 0.51279056]\n",
      " [ 0.4387652 ]\n",
      " [ 0.56089586]\n",
      " [ 0.47819605]] \n",
      "Correct:  [[ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]] \n",
      "Accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = [[0, 0],\n",
    "          [0, 1],\n",
    "          [1, 0],\n",
    "          [1, 1]]\n",
    "y_data = [[0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [0]]\n",
    "x_data = np.array(x_data, dtype=np.float32)\n",
    "y_data = np.array(y_data, dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2], name='x-input')\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name='y-input')\n",
    "\n",
    "with tf.name_scope(\"layer1\") as scope:\n",
    "    W1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
    "    b1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
    "    layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "    w1_hist = tf.summary.histogram(\"weights1\", W1)\n",
    "    b1_hist = tf.summary.histogram(\"biases1\", b1)\n",
    "    layer1_hist = tf.summary.histogram(\"layer1\", layer1)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"layer2\") as scope:\n",
    "    W2 = tf.Variable(tf.random_normal([2, 1]), name='weight2')\n",
    "    b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "    hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "    w2_hist = tf.summary.histogram(\"weights2\", W2)\n",
    "    b2_hist = tf.summary.histogram(\"biases2\", b2)\n",
    "    hypothesis_hist = tf.summary.histogram(\"hypothesis\", hypothesis)\n",
    "\n",
    "# cost/loss function\n",
    "with tf.name_scope(\"cost\") as scope:\n",
    "    cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *\n",
    "                           tf.log(1 - hypothesis))\n",
    "    cost_summ = tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "accuracy_summ = tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "# Launch graph\n",
    "sess = tf.Session()\n",
    "# tensorboard --logdir=./logs/xor_logs\n",
    "merged_summary = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"./logs/xor_logs_r0_01\")\n",
    "writer.add_graph(sess.graph)  # Show the graph\n",
    "\n",
    "# Initialize TensorFlow variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(10001):\n",
    "    summary, _ = sess.run([merged_summary, train], feed_dict={X: x_data, Y: y_data})\n",
    "    writer.add_summary(summary, global_step=step)\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(step, sess.run(cost, feed_dict={\n",
    "              X: x_data, Y: y_data}), sess.run([W1, W2]))\n",
    "\n",
    "# Accuracy report\n",
    "h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                   feed_dict={X: x_data, Y: y_data})\n",
    "print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard: Embedding Visualization\n",
    "###### https://www.tensorflow.org/get_started/embedding_viz\n",
    "coding from  \n",
    "https://github.com/tensorflow/tensorflow/issues/6322\n",
    "run tensorboard with  \n",
    "tensorboard --logdir=/tmp/tensorflow/mnist/logs/fully_connected_feed\n",
    "# another\n",
    "https://github.com/oduerr/dl_tutorial/blob/master/tensorflow/debugging/embedding.ipynb\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/input_data/t10k-labels-idx1-ubyte.gz\n",
      "Step 0: loss = 2.33 (0.023 sec)\n",
      "Step 100: loss = 2.22 (0.002 sec)\n",
      "Step 200: loss = 1.94 (0.002 sec)\n",
      "Step 300: loss = 1.73 (0.002 sec)\n",
      "Step 400: loss = 1.45 (0.002 sec)\n",
      "Step 500: loss = 1.04 (0.003 sec)\n",
      "Step 600: loss = 0.84 (0.002 sec)\n",
      "Step 700: loss = 0.77 (0.002 sec)\n",
      "Step 800: loss = 0.61 (0.002 sec)\n",
      "Step 900: loss = 0.64 (0.002 sec)\n",
      "Training Data Eval:\n",
      "  Num examples: 55000  Num correct: 47233  Precision @ 1: 0.8588\n",
      "Validation Data Eval:\n",
      "  Num examples: 5000  Num correct: 4329  Precision @ 1: 0.8658\n",
      "Test Data Eval:\n",
      "  Num examples: 10000  Num correct: 8706  Precision @ 1: 0.8706\n",
      "Step 1000: loss = 0.48 (0.006 sec)\n",
      "Step 1100: loss = 0.46 (0.076 sec)\n",
      "Step 1200: loss = 0.48 (0.003 sec)\n",
      "Step 1300: loss = 0.55 (0.003 sec)\n",
      "Step 1400: loss = 0.38 (0.002 sec)\n",
      "Step 1500: loss = 0.40 (0.006 sec)\n",
      "Step 1600: loss = 0.40 (0.003 sec)\n",
      "Step 1700: loss = 0.51 (0.002 sec)\n",
      "Step 1800: loss = 0.30 (0.002 sec)\n",
      "Step 1900: loss = 0.48 (0.002 sec)\n",
      "Training Data Eval:\n",
      "  Num examples: 55000  Num correct: 49336  Precision @ 1: 0.8970\n",
      "Validation Data Eval:\n",
      "  Num examples: 5000  Num correct: 4514  Precision @ 1: 0.9028\n",
      "Test Data Eval:\n",
      "  Num examples: 10000  Num correct: 9036  Precision @ 1: 0.9036\n",
      "Computing train Embedding\n",
      "  Num examples: 55000  Num correct: 49367  Precision @ 1: 0.8976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cine/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:312: DeprecationWarning: PyUnicode_AsEncodedObject() is deprecated; use PyUnicode_AsEncodedString() to encode from str to bytes or PyCodec_Encode() for generic encoding\n",
      "/home/cine/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:313: DeprecationWarning: PyUnicode_AsEncodedObject() is deprecated; use PyUnicode_AsEncodedString() to encode from str to bytes or PyCodec_Encode() for generic encoding\n",
      "/home/cine/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:314: DeprecationWarning: PyUnicode_AsEncodedObject() is deprecated; use PyUnicode_AsEncodedString() to encode from str to bytes or PyCodec_Encode() for generic encoding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing validation Embedding\n",
      "  Num examples: 5000  Num correct: 4514  Precision @ 1: 0.9028\n",
      "Computing test Embedding\n",
      "  Num examples: 10000  Num correct: 9036  Precision @ 1: 0.9036\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cine/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#\n",
    "# @author: Daniel Gordon <xkcd@cs.washington.edu>\n",
    "#\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"Trains and Evaluates the MNIST network using a feed dictionary.\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# pylint: disable=missing-docstring\n",
    "import argparse\n",
    "import os.path\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.examples.tutorials.mnist import mnist\n",
    "\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "\n",
    "# Basic model parameters as external flags.\n",
    "FLAGS = None\n",
    "\n",
    "\n",
    "def placeholder_inputs(batch_size):\n",
    "    \"\"\"Generate placeholder variables to represent the input tensors.\n",
    "  \n",
    "    These placeholders are used as inputs by the rest of the model building\n",
    "    code and will be fed from the downloaded data in the .run() loop, below.\n",
    "  \n",
    "    Args:\n",
    "      batch_size: The batch size will be baked into both placeholders.\n",
    "  \n",
    "    Returns:\n",
    "      images_placeholder: Images placeholder.\n",
    "      labels_placeholder: Labels placeholder.\n",
    "    \"\"\"\n",
    "    # Note that the shapes of the placeholders match the shapes of the full\n",
    "    # image and label tensors, except the first dimension is now batch_size\n",
    "    # rather than the full size of the train or test data sets.\n",
    "    images_placeholder = tf.placeholder(tf.float32, shape=(batch_size,\n",
    "                                                           mnist.IMAGE_PIXELS))\n",
    "    labels_placeholder = tf.placeholder(tf.int32, shape=(batch_size))\n",
    "    return images_placeholder, labels_placeholder\n",
    "\n",
    "\n",
    "def fill_feed_dict(data_set, images_pl, labels_pl):\n",
    "    \"\"\"Fills the feed_dict for training the given step.\n",
    "  \n",
    "    A feed_dict takes the form of:\n",
    "    feed_dict = {\n",
    "        <placeholder>: <tensor of values to be passed for placeholder>,\n",
    "        ....\n",
    "    }\n",
    "  \n",
    "    Args:\n",
    "      data_set: The set of images and labels, from input_data.read_data_sets()\n",
    "      images_pl: The images placeholder, from placeholder_inputs().\n",
    "      labels_pl: The labels placeholder, from placeholder_inputs().\n",
    "  \n",
    "    Returns:\n",
    "      feed_dict: The feed dictionary mapping from placeholders to values.\n",
    "    \"\"\"\n",
    "    # Create the feed_dict for the placeholders filled with the next\n",
    "    # `batch size` examples.\n",
    "    images_feed, labels_feed = data_set.next_batch(FLAGS.batch_size,\n",
    "                                                   FLAGS.fake_data)\n",
    "    feed_dict = {\n",
    "        images_pl: images_feed,\n",
    "        labels_pl: labels_feed,\n",
    "    }\n",
    "    return feed_dict\n",
    "\n",
    "\n",
    "def do_eval(sess,\n",
    "            eval_correct,\n",
    "            images_placeholder,\n",
    "            labels_placeholder,\n",
    "            data_set,\n",
    "            return_results=False):\n",
    "    \"\"\"Runs one evaluation against the full epoch of data.\n",
    "  \n",
    "    Args:\n",
    "      sess: The session in which the model has been trained.\n",
    "      eval_correct: The Tensor that returns the number of correct predictions.\n",
    "      images_placeholder: The images placeholder.\n",
    "      labels_placeholder: The labels placeholder.\n",
    "      data_set: The set of images and labels to evaluate, from\n",
    "        input_data.read_data_sets().\n",
    "      return_results: True if the results should be returned for the embedding.\n",
    "  \n",
    "    Returns:\n",
    "      all_images: A list of batches of images.\n",
    "      all_labels: A list of batches of labels.\n",
    "      all_hidden1_outputs: A list of batches of embeddings from the first hidden\n",
    "        layer.\n",
    "      all_hidden2_outputs: A list of batches of embeddings from the second hidden\n",
    "        layer.\n",
    "    \"\"\"\n",
    "    # And run one epoch of eval.\n",
    "    true_count = 0  # Counts the number of correct predictions.\n",
    "    steps_per_epoch = data_set.num_examples // FLAGS.batch_size\n",
    "    num_examples = steps_per_epoch * FLAGS.batch_size\n",
    "    if return_results:\n",
    "        all_images = []\n",
    "        all_labels = []\n",
    "        all_hidden1_outputs = []\n",
    "        all_hidden2_outputs = []\n",
    "        # Get the outputs before the ReLU.\n",
    "        hidden1_outputs = tf.get_default_graph().get_tensor_by_name('hidden1/add:0')\n",
    "        hidden2_outputs = tf.get_default_graph().get_tensor_by_name('hidden2/add:0')\n",
    "    for step in xrange(steps_per_epoch):\n",
    "        feed_dict = fill_feed_dict(data_set,\n",
    "                                   images_placeholder,\n",
    "                                   labels_placeholder)\n",
    "        if return_results:\n",
    "            all_images.append(feed_dict[images_placeholder])\n",
    "            all_labels.append(feed_dict[labels_placeholder])\n",
    "            curr_count, hidden1_output, hidden2_output = sess.run(\n",
    "                [eval_correct, hidden1_outputs, hidden2_outputs],\n",
    "                feed_dict=feed_dict)\n",
    "            true_count += curr_count\n",
    "            all_hidden1_outputs.append(hidden1_output)\n",
    "            all_hidden2_outputs.append(hidden2_output)\n",
    "        else:\n",
    "            true_count += sess.run(eval_correct, feed_dict=feed_dict)\n",
    "    precision = float(true_count) / num_examples\n",
    "    print('  Num examples: %d  Num correct: %d  Precision @ 1: %0.04f' %\n",
    "          (num_examples, true_count, precision))\n",
    "    if return_results:\n",
    "        return (all_images, all_labels, all_hidden1_outputs, all_hidden2_outputs)\n",
    "\n",
    "\n",
    "def images_to_sprite(data):\n",
    "    \"\"\"Creates the sprite image along with any necessary padding\n",
    "\n",
    "    Args:\n",
    "      data: NxHxW[x3] tensor containing the images.\n",
    "\n",
    "    Returns:\n",
    "      data: Properly shaped HxWx3 image with any necessary padding.\n",
    "    \"\"\"\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.tile(data[..., np.newaxis], (1, 1, 1, 3))\n",
    "    data = data.astype(np.float32)\n",
    "    min = np.min(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1, 2, 3, 0) - min).transpose(3, 0, 1, 2)\n",
    "    max = np.max(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1, 2, 3, 0) / max).transpose(3, 0, 1, 2)\n",
    "    # Inverting the colors seems to look better for MNIST\n",
    "    data = 1 - data\n",
    "\n",
    "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "    padding = ((0, n ** 2 - data.shape[0]), (0, 0),\n",
    "               (0, 0)) + ((0, 0),) * (data.ndim - 3)\n",
    "    data = np.pad(data, padding, mode='constant',\n",
    "                  constant_values=0)\n",
    "    # Tile the individual thumbnails into an image.\n",
    "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3)\n",
    "                                                           + tuple(range(4, data.ndim + 1)))\n",
    "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    return data\n",
    "\n",
    "\n",
    "def run_training():\n",
    "    \"\"\"Train MNIST for a number of steps.\"\"\"\n",
    "    # Get the sets of images and labels for training, validation, and\n",
    "    # test on MNIST.\n",
    "    data_sets = input_data.read_data_sets(FLAGS.input_data_dir, FLAGS.fake_data)\n",
    "\n",
    "    # Tell TensorFlow that the model will be built into the default Graph.\n",
    "    with tf.Graph().as_default():\n",
    "        # Generate placeholders for the images and labels.\n",
    "        images_placeholder, labels_placeholder = placeholder_inputs(\n",
    "            FLAGS.batch_size)\n",
    "\n",
    "        # Build a Graph that computes predictions from the inference model.\n",
    "        logits = mnist.inference(images_placeholder,\n",
    "                                 FLAGS.hidden1,\n",
    "                                 FLAGS.hidden2)\n",
    "\n",
    "        # Add to the Graph the Ops for loss calculation.\n",
    "        loss = mnist.loss(logits, labels_placeholder)\n",
    "\n",
    "        # Add to the Graph the Ops that calculate and apply gradients.\n",
    "        train_op = mnist.training(loss, FLAGS.learning_rate)\n",
    "\n",
    "        # Add the Op to compare the logits to the labels during evaluation.\n",
    "        eval_correct = mnist.evaluation(logits, labels_placeholder)\n",
    "\n",
    "        # Build the summary Tensor based on the TF collection of Summaries.\n",
    "        summary = tf.summary.merge_all()\n",
    "\n",
    "        # Add the variable initializer Op.\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        # Create a saver for writing training checkpoints.\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        # Create a session for running Ops on the Graph.\n",
    "        sess = tf.Session()\n",
    "\n",
    "        # Instantiate a SummaryWriter to output summaries and the Graph.\n",
    "        summary_writer = tf.summary.FileWriter(FLAGS.log_dir, sess.graph)\n",
    "\n",
    "        # And then after everything is built:\n",
    "\n",
    "        # Run the Op to initialize the variables.\n",
    "        sess.run(init)\n",
    "\n",
    "        # Start the training loop.\n",
    "        for step in xrange(FLAGS.max_steps):\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Fill a feed dictionary with the actual set of images and labels\n",
    "            # for this particular training step.\n",
    "            feed_dict = fill_feed_dict(data_sets.train,\n",
    "                                       images_placeholder,\n",
    "                                       labels_placeholder)\n",
    "\n",
    "            # Run one step of the model.  The return values are the activations\n",
    "            # from the `train_op` (which is discarded) and the `loss` Op.  To\n",
    "            # inspect the values of your Ops or variables, you may include them\n",
    "            # in the list passed to sess.run() and the value tensors will be\n",
    "            # returned in the tuple from the call.\n",
    "            _, loss_value = sess.run([train_op, loss],\n",
    "                                     feed_dict=feed_dict)\n",
    "\n",
    "            duration = time.time() - start_time\n",
    "\n",
    "            # Write the summaries and print an overview fairly often.\n",
    "            if step % 100 == 0:\n",
    "                # Print status to stdout.\n",
    "                print('Step %d: loss = %.2f (%.3f sec)' % (step, loss_value, duration))\n",
    "                # Update the events file.\n",
    "                summary_str = sess.run(summary, feed_dict=feed_dict)\n",
    "                summary_writer.add_summary(summary_str, step)\n",
    "                summary_writer.flush()\n",
    "\n",
    "            # Save a checkpoint and evaluate the model periodically.\n",
    "            if (step + 1) % 1000 == 0 or (step + 1) == FLAGS.max_steps:\n",
    "                checkpoint_file = os.path.join(FLAGS.log_dir, 'model.ckpt')\n",
    "                saver.save(sess, checkpoint_file, global_step=step)\n",
    "                # Evaluate against the training set.\n",
    "                print('Training Data Eval:')\n",
    "                do_eval(sess,\n",
    "                        eval_correct,\n",
    "                        images_placeholder,\n",
    "                        labels_placeholder,\n",
    "                        data_sets.train)\n",
    "                # Evaluate against the validation set.\n",
    "                print('Validation Data Eval:')\n",
    "                do_eval(sess,\n",
    "                        eval_correct,\n",
    "                        images_placeholder,\n",
    "                        labels_placeholder,\n",
    "                        data_sets.validation)\n",
    "                # Evaluate against the test set.\n",
    "                print('Test Data Eval:')\n",
    "                do_eval(sess,\n",
    "                        eval_correct,\n",
    "                        images_placeholder,\n",
    "                        labels_placeholder,\n",
    "                        data_sets.test)\n",
    "\n",
    "        # Compute embeddings and save them.\n",
    "        thumbnail_size = int(np.sqrt(mnist.IMAGE_PIXELS))\n",
    "        for data_set, name in [\n",
    "            (data_sets.train, 'train'),\n",
    "            (data_sets.validation, 'validation'),\n",
    "            (data_sets.test, 'test')]:\n",
    "            output_path = os.path.join(FLAGS.log_dir, 'embed', name)\n",
    "            print('Computing %s Embedding' % name)\n",
    "            (all_images, all_labels, hidden1_vectors, hidden2_vectors) = do_eval(\n",
    "                sess,\n",
    "                eval_correct,\n",
    "                images_placeholder,\n",
    "                labels_placeholder,\n",
    "                data_set,\n",
    "                True)\n",
    "            embed_tensors = []\n",
    "            summary_writer = tf.summary.FileWriter(output_path, sess.graph)\n",
    "            config = projector.ProjectorConfig()\n",
    "            for layer, embed_vectors in enumerate([hidden1_vectors, hidden2_vectors]):\n",
    "                embed_tensor = tf.Variable(\n",
    "                    np.array(embed_vectors).reshape(\n",
    "                        len(embed_vectors) * embed_vectors[0].shape[0], -1),\n",
    "                    name=('%s_layer_%s' % (name, layer)))\n",
    "                embed_tensors.append(embed_tensor)\n",
    "                sess.run(embed_tensor.initializer)\n",
    "                embedding = config.embeddings.add()\n",
    "                embedding.tensor_name = embed_tensor.name\n",
    "                embedding.metadata_path = os.path.join(output_path, 'labels.tsv')\n",
    "                embedding.sprite.image_path = os.path.join(output_path, 'sprite.png')\n",
    "                embedding.sprite.single_image_dim.extend(\n",
    "                    [thumbnail_size, thumbnail_size])\n",
    "                projector.visualize_embeddings(summary_writer, config)\n",
    "            result = sess.run(embed_tensors)\n",
    "            saver = tf.train.Saver(embed_tensors)\n",
    "            saver.save(sess, os.path.join(output_path, 'model.ckpt'), layer)\n",
    "\n",
    "            # Make sprite and labels.\n",
    "            images = np.array(all_images).reshape(\n",
    "                -1, thumbnail_size, thumbnail_size).astype(np.float32)\n",
    "            sprite = images_to_sprite(images)\n",
    "            scipy.misc.imsave(os.path.join(output_path, 'sprite.png'), sprite)\n",
    "            all_labels = np.array(all_labels).flatten()\n",
    "            metadata_file = open(os.path.join(output_path, 'labels.tsv'), 'w')\n",
    "            metadata_file.write('Name\\tClass\\n')\n",
    "            for ll in xrange(len(all_labels)):\n",
    "                metadata_file.write('%06d\\t%d\\n' % (ll, all_labels[ll]))\n",
    "            metadata_file.close()\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    if tf.gfile.Exists(FLAGS.log_dir):\n",
    "        tf.gfile.DeleteRecursively(FLAGS.log_dir)\n",
    "    tf.gfile.MakeDirs(FLAGS.log_dir)\n",
    "    run_training()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--learning_rate',\n",
    "        type=float,\n",
    "        default=0.01,\n",
    "        help='Initial learning rate.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--max_steps',\n",
    "        type=int,\n",
    "        default=2000,\n",
    "        help='Number of steps to run trainer.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--hidden1',\n",
    "        type=int,\n",
    "        default=128,\n",
    "        help='Number of units in hidden layer 1.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--hidden2',\n",
    "        type=int,\n",
    "        default=32,\n",
    "        help='Number of units in hidden layer 2.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--batch_size',\n",
    "        type=int,\n",
    "        default=100,\n",
    "        help='Batch size.  Must divide evenly into the dataset sizes.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--input_data_dir',\n",
    "        type=str,\n",
    "        default='./mnist/input_data',\n",
    "        help='Directory to put the input data.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--log_dir',\n",
    "        type=str,\n",
    "        default='./logs/fully_connected_feed',\n",
    "        help='Directory to put the log data.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--fake_data',\n",
    "        default=False,\n",
    "        help='If true, uses fake data for unit testing.',\n",
    "        action='store_true'\n",
    "    )\n",
    "\n",
    "    FLAGS, unparsed = parser.parse_known_args()\n",
    "    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
